"""
DATASET MANAGER
Automated downloading and handling of surveillance benchmarks:
- UCF-Crime
- ShanghaiTech
- UCSD Anomaly
- Avenue
"""
import os
import requests
import zipfile
import tarfile

class DatasetManager:
    def __init__(self, base_path='datasets'):
        self.base_path = base_path
        os.makedirs(base_path, exist_ok=True)
        
        self.sources = {
            'Avenue': 'http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/Avenue_Dataset.zip',
            'UCSD': 'http://www.svcl.ucsd.edu/projects/anomaly/UCSD_Anomaly_Dataset.tar.gz',
            # UCF and ShanghaiTech often require drive links or kaggle API, using placeholders for logic
            'ShanghaiTech': 'https://example.com/shanghaitech.zip', 
            'UCF_Crime': 'https://example.com/ucf_crime.zip'
        }
        
    def download_dataset(self, name):
        """Download and extract a specific dataset"""
        if name not in self.sources:
            print(f"‚ùå Dataset {name} not known.")
            return False
            
        url = self.sources[name]
        filename = os.path.join(self.base_path, url.split('/')[-1])
        extract_path = os.path.join(self.base_path, name)
        
        if os.path.exists(extract_path):
            print(f"‚úÖ {name} already exists at {extract_path}")
            return True
            
        print(f"‚¨áÔ∏è Downloading {name} from {url}...")
        try:
            # Simulation for non-direct links to avoid huge downloads blocking execution
            if 'example.com' in url:
                print(f"‚ö†Ô∏è {name} requires manual download or Kaggle API. Created placeholder.")
                os.makedirs(extract_path, exist_ok=True)
                return True
                
            # Real download logic
            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                with open(filename, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        
            print(f"üì¶ Extracting {name}...")
            if filename.endswith('.zip'):
                with zipfile.ZipFile(filename, 'r') as zip_ref:
                    zip_ref.extractall(self.base_path)
            elif filename.endswith('.tar.gz'):
                with tarfile.open(filename, "r:gz") as tar:
                    tar.extractall(self.base_path)
                    
            print(f"‚úÖ {name} ready.")
            return True
            
        except Exception as e:
            print(f"‚ùå Failed to download {name}: {e}")
            return False

    def list_videos(self, name):
        """Return list of video files in a dataset"""
        path = os.path.join(self.base_path, name)
        videos = []
        for root, dirs, files in os.walk(path):
            for file in files:
                if file.endswith(('.mp4', '.avi', '.mov')):
                    videos.append(os.path.join(root, file))
        return videos

if __name__ == "__main__":
    dm = DatasetManager()
    print("üöÄ Auto-downloading Datasets...")
    dm.download_dataset('Avenue') # Avenue is most reliable direct link
    # dm.download_dataset('UCSD') # UCSD is reliable but large
